stages:
  etl_pipeline_full:
    cmd: python src/data_handling/etl_pipeline.py

    deps:
      - src/data_handling/etl_pipeline.py
      - src/data_handling/
      - src/_utils/

    outs:
      - data/original_df.parquet
      - data/processed_df.parquet

  etl_pipeline_stockcode:
    cmd: python src/data_handling/etl_pipeline.py --stockcode ${params.stockcode}

    deps:
      - src/data_handling/etl_pipeline.py
      - src/data_handling/
      - src/_utils/

    params:
      - params.stockcode

    outs:
      - data/processed_df_${params.stockcode}.parquet

  data_drift_check:
    cmd: >
      python src/data_handling/report_data_drift.py
      data/processed/processed_df.csv
      data/processed_df_${params.stockcode}.parquet
      reports/data_drift_report_${params.stockcode}.html
      metrics/data_drift_metrics_${params.stockcode}.json
      ${params.stockcode}

    params:
      - params.stockcode

    deps:
      - src/data_handling/report_data_drift.py
      - src/data_handling/scripts/
      - src/_utils/
      - data/

    plots:
      - reports/data_drift_report_${params.stockcode}.html: # dvc plots the results
          cache: true # large file - cache

    metrics:
      - metrics/data_drift_metrics_${params.stockcode}.json: # dvc tracks and versions the metrics
          type: json

  preprocess_full:
    cmd: >
      python src/data_handling/preprocess.py --target_col ${params.target_col} --should_scale ${params.should_scale} --verbose ${params.verbose}

    deps:
      - src/data_handling/preprocess.py
      - src/data_handling/
      - src/_utils

    # params from params.yaml
    params:
      - params.target_col
      - params.should_scale
      - params.verbose

    outs:
      # train, val, test datasets
      - data/x_train_df.parquet
      - data/x_val_df.parquet
      - data/x_test_df.parquet
      - data/y_train_df.parquet
      - data/y_val_df.parquet
      - data/y_test_df.parquet

      # preprocessed input datasets
      - data/x_train_processed.parquet
      - data/x_val_processed.parquet
      - data/x_test_processed.parquet

      # fitted preprocessor and feature names for shap analysis
      - preprocessors/column_transformer.pkl
      - preprocessors/feature_names.json

  preprocess_stockcode:
    cmd: >
      python src/data_handling/preprocess.py --target_col ${params.target_col} --should_scale ${params.should_scale} --verbose ${params.verbose} --stockcode ${params.stockcode}

    deps:
      - src/data_handling/preprocess.py
      - src/data_handling/
      - src/_utils

    # params from params.yaml
    params:
      - params.target_col
      - params.should_scale
      - params.verbose
      - params.stockcode

    outs:
      # train, val, test datasets
      - data/x_train_df_${params.stockcode}.parquet
      - data/x_val_df_${params.stockcode}.parquet
      - data/x_test_df_${params.stockcode}.parquet
      - data/y_train_df_${params.stockcode}.parquet
      - data/y_val_df_${params.stockcode}.parquet
      - data/y_test_df_${params.stockcode}.parquet

      # processed input datasets
      - data/x_train_processed_${params.stockcode}.parquet
      - data/x_val_processed_${params.stockcode}.parquet
      - data/x_test_processed_${params.stockcode}.parquet

  tune_primary_model:
    cmd: >
      python src/model/torch_model/main.py
      data/x_train_processed_${params.stockcode}.parquet
      data/x_val_processed_${params.stockcode}.parquet
      data/y_train_df_${params.stockcode}.parquet
      data/y_val_df_${params.stockcode}.parquet
      ${tuning.should_local_save}
      ${tuning.grid}
      ${tuning.n_trials}
      ${tuning.num_epochs}
      ${params.stockcode}

    deps:
      - src/model/torch_model/main.py
      - src/data_handling/
      - src/model/
      - src/_utils/

    params:
      - params.stockcode
      - tuning.n_trials
      - tuning.grid
      - tuning.should_local_save

    outs:
      - models/production/dfn_best_${params.stockcode}.pth # dvc track

    metrics:
      - metrics/val_${params.stockcode}.json: # dvc track
          cache: false # file size is small. skip dvc cache

  inference_primary_model:
    cmd: >
      python src/model/torch_model/inference.py
      data/x_test_processed_${params.stockcode}.parquet
      data/y_test_df_${params.stockcode}.parquet
      models/production/dfn_best_${params.stockcode}.pth
      ${params.stockcode}

    deps:
      - src/model/torch_model/inference.py
      - models/production/
      - src/model/
      - src/_utils/

    # params:
    #   - params.inference_start_date

    metrics:
      - metrics/dfn_inference_results_${params.stockcode}.json: # dvc track
          type: json

    plots:
      # shap summary / beeswarm plot for global interpretability
      - reports/dfn_shap_summary_${params.stockcode}.json:
          template: simple
          x: shap_value
          y: feature_name
          title: SHAP Beeswarm Plot

      # shap mean absolute vals - feature importance bar plot
      - reports/dfn_shap_mean_abs_${params.stockcode}.json:
          template: bar
          x: mean_abs_shap
          y: feature_name
          title: Mean Absolute SHAP Importance

    outs:
      - data/dfn_inference_results_${params.stockcode}.parquet # y_pred
      - reports/dfn_raw_shap_values_${params.stockcode}.parquet # save raw shap vals for detailed analysis later
